{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corriendo Algoritmo de descenso de gradiente ...\n",
      "\n",
      "Vaores de theta obtenidos del Algoritmo:\n",
      "\n",
      "-3.630291\n",
      "1.166362\n",
      "\n",
      "Valores esperados de theta (approx)\n",
      " -3.6303\n",
      "  1.1664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "function J = computeCost(X, y, theta)\n",
    "m = length(y); % number of training examples\n",
    "J = 0;\n",
    "\n",
    "producto = X * theta;\n",
    "resta = sum((producto-y).^2);\n",
    "J= resta/(2*m);\n",
    "end\n",
    "\n",
    "function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)\n",
    "%GRADIENTDESCENT Performs gradient descent to learn theta\n",
    "%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "%   taking num_iters gradient steps with learning rate alpha\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "J_history = zeros(num_iters, 1);\n",
    "\n",
    "for iter = 1:num_iters\n",
    "\n",
    "    producto = X * theta;\n",
    "    dis = producto -y;\n",
    "    st0 = sum((dis .* X(:,1)));\n",
    "    st1 = sum((dis .* X(:,2)));\n",
    "    t0 = theta(1,1) - (alpha * st0)/m;\n",
    "    t1 = theta(2,1) - (alpha * st1)/m;\n",
    "    theta = [t0;t1];\n",
    "    J_history(iter) = computeCost(X, y, theta);\n",
    "\n",
    "end\n",
    "end\n",
    "\n",
    "data = load('../../ML-ex1/ex1data1.txt');\n",
    "X = data(:, 1);\n",
    "\n",
    "y = data(:, 2);\n",
    "m = length(y); % number of training examples\n",
    "X = [ones(m, 1), data(:,1)]; % Add a column of ones to x\n",
    "theta = zeros(2, 1);\n",
    "iterations = 1500;\n",
    "alpha = 0.01;\n",
    "fprintf('\\nCorriendo Algoritmo de descenso de gradiente ...\\n\\n')\n",
    "% run gradient descent\n",
    "theta = gradientDescent(X, y, theta, alpha, iterations);\n",
    "\n",
    "% print theta to screen\n",
    "fprintf('Vaores de theta obtenidos del Algoritmo:\\n\\n');\n",
    "fprintf('%f\\n', theta);\n",
    "fprintf('\\nValores esperados de theta (approx)\\n');\n",
    "fprintf(' -3.6303\\n  1.1664\\n\\n');\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
